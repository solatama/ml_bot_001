# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import talib
import time
import optuna
import lightgbm as lgb
import xgboost as xgb
import catboost as cb
from sklearn.ensemble import RandomForestRegressor, StackingRegressor, VotingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# === å®šæ•°å®šç¾© ===
TICKER = '9684.T'
START_DATE = '2024-04-01'
END_DATE = '2025-04-10'
INTERVAL = '1d'

FEATURES = ['close_scaled']
STOP_LOSS_MODE = 1  # 1: å›ºå®šãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæåˆ‡ã‚Š, 2: ãƒ‘ãƒ©ãƒœãƒªãƒƒã‚¯SARæåˆ‡ã‚Š, 3: ç›´è¿‘å®‰å€¤æ›´æ–°
STOP_LOSS = 0.02    # å›ºå®šãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæåˆ‡ã‚Šã§ã®æå¤±è¨±å®¹ç‡ï¼ˆä¾‹: 2%ï¼‰
TAKE_PROFIT = 0.04  # åˆ©ç¢ºå¹…ï¼ˆä¾‹: 4%ï¼‰
COMMISSION = 0.0005  # æ‰‹æ•°æ–™ç‡ï¼ˆå¿…è¦ãªã‚‰è¨­å®šï¼‰
SLIPPAGE = 0.0005    # ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ç‡ï¼ˆå¿…è¦ãªã‚‰è¨­å®šï¼‰
SELECTED_MODELS = ['xgboost', 'randomforest', 'catboost', 'lightgbm', 'rnn', 'transformer']
ENSEMBLE_TYPE = 'stacking'  # 'blending', 'stacking', 'voting_hard', 'voting_soft'ã‹ã‚‰é¸æŠ

# yfinanceã‚’ä½¿ã£ã¦æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
def get_data(ticker, start_date, end_date, interval='1d'):
    df = yf.download(ticker, start=start_date, end=end_date, interval=interval)
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']]

    # MultiIndex ã®å ´åˆã«ãƒªã‚»ãƒƒãƒˆ
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(0)

    # åˆ—åã‚’å°æ–‡å­—ã«å¤‰æ›
    df.columns = [col.lower() for col in df.columns]
    return df

# ãƒ‡ãƒ¼ã‚¿å–å¾—
df = get_data(TICKER, START_DATE, END_DATE, INTERVAL)
df.head()

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆMinMaxScalerã‚’ä½¿ç”¨ï¼‰
def preprocess_data(df):
    scaler = MinMaxScaler()
    df['close_scaled'] = scaler.fit_transform(df[['close']])
    return df

def calc_features(df):
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"å¿…è¦ãªåˆ—ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“: {missing_columns}")

    # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’å–å¾—ã—ã€numpy.ndarray å‹ã«å¤‰æ›
    open_col = df['open'].values.astype(float)
    high_col = df['high'].values.astype(float)
    low_col = df['low'].values.astype(float)
    close_col = df['close'].values.astype(float)
    volume = df['volume'].values.astype(float)

    orig_columns = df.columns

    hilo = (df['high'] + df['low']) / 2
    # ä¾¡æ ¼(hilo ã¾ãŸã¯ close)ã‚’å¼•ã„ãŸå¾Œã€ä¾¡æ ¼(close)ã§å‰²ã‚‹ã“ã¨ã§æ¨™æº–åŒ–ã—ã¦ã‚‹ã‚‚ã®ã‚ã‚Š

    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
    df['BBANDS_upperband'], df['BBANDS_middleband'], df['BBANDS_lowerband'] = talib.BBANDS(df['close'], timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)
    df['BBANDS_upperband'] = (df['BBANDS_upperband'] - hilo) / df['close']
    df['BBANDS_middleband'] = (df['BBANDS_middleband'] - hilo) / df['close']
    df['BBANDS_lowerband'] = (df['BBANDS_lowerband'] - hilo) / df['close']

    # ç§»å‹•å¹³å‡
    df['DEMA'] = (talib.DEMA(close_col, timeperiod=30) - hilo) / close_col
    df['EMA'] = (talib.EMA(close_col, timeperiod=30) - hilo) / close_col
    df['EMA_short'] = (talib.EMA(close_col, timeperiod=5) - hilo) / close_col
    df['EMA_middle'] = (talib.EMA(close_col, timeperiod=20) - hilo) / close_col
    df['EMA_long'] = (talib.EMA(close_col, timeperiod=40) - hilo) / close_col
    df['HT_TRENDLINE'] = (talib.HT_TRENDLINE(close_col) - hilo) / close_col
    df['KAMA'] = (talib.KAMA(close_col, timeperiod=30) - hilo) / close_col
    df['MA'] = (talib.MA(close_col, timeperiod=30, matype=0) - hilo) / close_col
    df['MIDPOINT'] = (talib.MIDPOINT(close_col, timeperiod=14) - hilo) / close_col
    df['SMA'] = (talib.SMA(close_col, timeperiod=30) - hilo) / close_col
    df['T3'] = (talib.T3(close_col, timeperiod=5, vfactor=0) - hilo) / close_col
    df['HMA'] = talib.WMA(close_col, timeperiod=30)
    df['TEMA'] = (talib.TEMA(close_col, timeperiod=30) - hilo) / close_col
    df['TRIMA'] = (talib.TRIMA(close_col, timeperiod=30) - hilo) / close_col
    df['WMA'] = (talib.WMA(close_col, timeperiod=30) - hilo) / close_col

    # MACD
    df['MACD_macd'], df['MACD_macdsignal'], df['MACD_macdhist'] = talib.MACD(close_col, fastperiod=12, slowperiod=26, signalperiod=9) # Use close_col instead of close
    df['MACD_macd'] /= close_col # Use close_col instead of close
    df['MACD_macdsignal'] /= close_col # Use close_col instead of close
    df['MACD_macdhist'] /= close_col # Use close_col instead of close
    df['MACD_EXT'], df['MACD_SIGNAL_EXT'], df['MACD_HIST_EXT'] = talib.MACDEXT(close_col, fastperiod=12, slowperiod=26, signalperiod=9, fastmatype=0, slowmatype=0, signalmatype=0) # Use close_col instead of close

    # ç·šå½¢å›å¸°ç³»
    df['LINEARREG'] = (talib.LINEARREG(close_col, timeperiod=14) - close_col) / close_col # Use close_col instead of close
    df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(close_col, timeperiod=14) / close_col # Use close_col instead of close
    df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(close_col, timeperiod=14) # Use close_col instead of close
    df['LINEARREG_INTERCEPT'] = (talib.LINEARREG_INTERCEPT(close_col, timeperiod=14) - close_col) / close_col # Use close_col instead of close

    # ADç³»
    df['AD'] = talib.AD(high_col, low_col, close_col, volume) / close_col # Use high_col, low_col, close_col instead of high, low, close
    df['ADX'] = talib.ADX(high_col, low_col, close_col, timeperiod=14) # Use high_col, low_col, close_col instead of high, low, close
    df['ADXR'] = talib.ADXR(high_col, low_col, close_col, timeperiod=14) # Use high_col, low_col, close_col instead of high, low, close
    df['ADOSC'] = talib.ADOSC(high_col, low_col, close_col, volume, fastperiod=3, slowperiod=10) / close_col # Use high_col, low_col, close_col instead of high, low, close
    df['OBV'] = talib.OBV(close_col, volume) / close_col # Use close_col instead of close

    # ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼ç³»
    df['APO'] = talib.APO(close_col, fastperiod=12, slowperiod=26, matype=0) / close_col  # Changed close to close_col
    df['BOP'] = talib.BOP(open_col, high_col, low_col, close_col)  # Changed open, high, low, close to their respective _col variables
    df['CCI'] = talib.CCI(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['DX'] = talib.DX(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['MFI'] = talib.MFI(high_col, low_col, close_col, volume, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['MINUS_DI'] = talib.MINUS_DI(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['PLUS_DI'] = talib.PLUS_DI(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['MOM'] = talib.MOM(close_col, timeperiod=10) / close_col  # Changed close to close_col
    df['RSI'] = talib.RSI(close_col, timeperiod=14)  # Changed close to close_col
    df['TRIX'] = talib.TRIX(close_col, timeperiod=30)  # Changed close to close_col
    df['ULTOSC'] = talib.ULTOSC(high_col, low_col, close_col, timeperiod1=7, timeperiod2=14, timeperiod3=28)  # Changed high, low, close to their respective _col variables
    df['WILLR'] = talib.WILLR(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['SAR'] = talib.SAR(high_col, low_col, acceleration=0.02, maximum=0.2)  # Changed high, low to their respective _col variables

    # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
    df['STOCH_slowk'], df['STOCH_slowd'] = talib.STOCH(high_col, low_col, close_col, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0) # Changed high, low, close to high_col, low_col, close_col
    df['STOCHF_fastk'], df['STOCHF_fastd'] = talib.STOCHF(high_col, low_col, close_col, fastk_period=5, fastd_period=3, fastd_matype=0) # Changed high, low, close to high_col, low_col, close_col
    df['STOCHRSI_fastk'], df['STOCHRSI_fastd'] = talib.STOCHRSI(close_col, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0) # Changed close to close_col

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»
    df['MINUS_DM'] = talib.MINUS_DM(high_col, low_col, timeperiod=14) / close_col # Changed high, low, close to high_col, low_col, close_col
    df['PLUS_DM'] = talib.PLUS_DM(high_col, low_col, timeperiod=14) / close_col # Changed high, low, close to high_col, low_col, close_col
    df['STDDEV'] = talib.STDDEV(close_col, timeperiod=5, nbdev=1) # Changed close to close_col
    df['TRANGE'] = talib.TRANGE(high_col, low_col, close_col) # Changed high, low, close to high_col, low_col, close_col
    df['VAR'] = talib.VAR(close_col, timeperiod=5, nbdev=1) # Changed close to close_col
    df['ATR'] = talib.ATR(high_col, low_col, close_col, timeperiod=14) # Changed high, low, close to high_col, low_col, close_col
    df['NATR'] = talib.NATR(high_col, low_col, close_col, timeperiod=14) # Changed high, low, close to high_col, low_col, close_col
    df['VOLATILITY_index'] = df['ATR'] / df['STDDEV']

    # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›
    df['HT_DCPERIOD'] = talib.HT_DCPERIOD(close_col) # Changed close to close_col
    df['HT_DCPHASE'] = talib.HT_DCPHASE(close_col) # Changed close to close_col
    df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = talib.HT_PHASOR(close_col) # Changed close to close_col
    df['HT_PHASOR_inphase'] /= close_col # Changed close to close_col
    df['HT_PHASOR_quadrature'] /= close_col # Changed close to close_col
    df['HT_SINE_sine'], df['HT_SINE_leadsine'] = talib.HT_SINE(close_col) # Changed close to close_col
    df['HT_SINE_sine'] /= close_col # Changed close to close_col
    df['HT_SINE_leadsine'] /= close_col # Changed close to close_col
    df['HT_TRENDMODE'] = talib.HT_TRENDMODE(close_col) # Changed close to close_col

    # ãã®ä»–
    df['ROC'] = talib.ROC(close_col, timeperiod=10) / close_col # Changed close to close_col
    df['STDDEV'] = talib.STDDEV(close_col, timeperiod=5, nbdev=1) / close_col # Changed close to close_col
    df['TRANGE'] = talib.TRANGE(high_col, low_col, close_col) / close_col # Changed high, low, close to high_col, low_col, close_col
    df['AROON_aroondown'], df['AROON_aroonup'] = talib.AROON(high_col, low_col, timeperiod=14) # Changed high, low to high_col, low_col
    df['AROONOSC'] = talib.AROONOSC(high_col, low_col, timeperiod=14) # Changed high, low to high_col, low_col
    df['BETA'] = talib.BETA(high_col, low_col, timeperiod=5) # Changed high, low to high_col, low_col
    df['CORREL'] = talib.CORREL(high_col, low_col, timeperiod=30) # Changed high, low to high_col, low_col
    df['Price_ratio'] = df['close'] / df['close'].shift(1)  # Changed df[close_col] to df['close']
    df['HIGH_ratio'] = df['high'] / df['high'].shift(1)  # Changed df[high_col] to df['high']
    df['LOW_ratio'] = df['low'] / df['low'].shift(1)  # Changed df[low_col] to df['low']

    # Lagç‰¹å¾´é‡
    df['CLOSE_lag_1'] = df['close'].shift(1)  # 1æ—¥é…ã‚Œã®çµ‚å€¤ # Changed df[close_col] to df['close']
    df['CLOSE_lag_5'] = df['close'].shift(5)  # 5æ—¥é…ã‚Œã®çµ‚å€¤ # Changed df[close_col] to df['close']
    df['MOVIENG_avg_5'] = df['close'].rolling(window=5).mean()  # 5æ—¥ç§»å‹•å¹³å‡ # Changed df[close_col] to df['close']
    # å‘¨æœŸæ€§ã®ç‰¹å¾´é‡
    df['DAY_of_week'] = df.index.dayofweek  # æ›œæ—¥ï¼ˆ0=æœˆæ›œæ—¥, 6=æ—¥æ›œæ—¥ï¼‰
    df['IS_weekend'] = (df['DAY_of_week'] >= 5).astype(int)  # é€±æœ«ã‹ã©ã†ã‹
    df['MONTH'] = df.index.month  # æœˆï¼ˆ1ã€œ12ï¼‰
    df['SIN_day'] = np.sin(2 * np.pi * df['DAY_of_week'] / 7)  # æ—¥å‘¨æœŸ
    df['COS_day'] = np.cos(2 * np.pi * df['DAY_of_week'] / 7)  # æ—¥å‘¨æœŸ
    df['SIN_month'] = np.sin(2 * np.pi * df['MONTH'] / 12)  # æœˆå‘¨æœŸ
    df['COS_month'] = np.cos(2 * np.pi * df['MONTH'] / 12)  # æœˆå‘¨æœŸ

    # ãƒªã‚¿ãƒ¼ãƒ³ç³»
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    df['return_1d'] = df['close'].pct_change(1)
    df['return_5d'] = df['close'].pct_change(5)
    df['return_10d'] = df['close'].pct_change(10)
    df['return_20d'] = df['close'].pct_change(20)

    df['return_ma_5'] = df['return_1d'].rolling(window=5).mean()
    df['return_ma_10'] = df['return_1d'].rolling(window=10).mean()

    df['volatility_5'] = df['close'].rolling(window=5).std()
    df['volatility_10'] = df['close'].rolling(window=10).std()

    df['range'] = df['high'] - df['low']

    df['volume_change'] = df['volume'].pct_change(1)

    # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»
    df['ma_5'] = df['close'].rolling(window=5).mean()
    df['ma_25'] = df['close'].rolling(window=25).mean()
    df['ma_75'] = df['close'].rolling(window=75).mean()

    df['ma_deviation_5'] = df['close'] / df['ma_5'] - 1
    df['ma_deviation_25'] = df['close'] / df['ma_25'] - 1
    df['ma_deviation_75'] = df['close'] / df['ma_75'] - 1

    # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆnæ—¥å‰æ¯”ï¼‰
    df['momentum_5'] = df['close'] - df['close'].shift(5)
    df['momentum_10'] = df['close'] - df['close'].shift(10)
    df['momentum_20'] = df['close'] - df['close'].shift(20)

    # --- ãƒ­ãƒ¼ã‚½ã‚¯è¶³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ50ç¨®é¡ï¼‰---
    # å€¤ã¯ +100: å¼·æ°—ã‚·ã‚°ãƒŠãƒ«, -100: å¼±æ°—ã‚·ã‚°ãƒŠãƒ«, 0: ã‚·ã‚°ãƒŠãƒ«ãªã—
    candlestick_patterns = {
        'CDL2CROWS': talib.CDL2CROWS,
        'CDL3BLACKCROWS': talib.CDL3BLACKCROWS,
        'CDL3INSIDE': talib.CDL3INSIDE,
        'CDL3LINESTRIKE': talib.CDL3LINESTRIKE,
        'CDL3OUTSIDE': talib.CDL3OUTSIDE,
        'CDL3STARSINSOUTH': talib.CDL3STARSINSOUTH,
        'CDL3WHITESOLDIERS': talib.CDL3WHITESOLDIERS,
        'CDLABANDONEDBABY': talib.CDLABANDONEDBABY,
        'CDLADVANCEBLOCK': talib.CDLADVANCEBLOCK,
        'CDLBELTHOLD': talib.CDLBELTHOLD,
        'CDLBREAKAWAY': talib.CDLBREAKAWAY,
        'CDLCLOSINGMARUBOZU': talib.CDLCLOSINGMARUBOZU,
        'CDLCONCEALBABYSWALL': talib.CDLCONCEALBABYSWALL,
        'CDLCOUNTERATTACK': talib.CDLCOUNTERATTACK,
        'CDLDARKCLOUDCOVER': talib.CDLDARKCLOUDCOVER,
        'CDLDOJI': talib.CDLDOJI,
        'CDLDOJISTAR': talib.CDLDOJISTAR,
        'CDLDRAGONFLYDOJI': talib.CDLDRAGONFLYDOJI,
        'CDLENGULFING': talib.CDLENGULFING,
        'CDLEVENINGDOJISTAR': talib.CDLEVENINGDOJISTAR,
        'CDLEVENINGSTAR': talib.CDLEVENINGSTAR,
        'CDLGAPSIDESIDEWHITE': talib.CDLGAPSIDESIDEWHITE,
        'CDLGRAVESTONEDOJI': talib.CDLGRAVESTONEDOJI,
        'CDLHAMMER': talib.CDLHAMMER,
        'CDLHANGINGMAN': talib.CDLHANGINGMAN,
        'CDLHARAMI': talib.CDLHARAMI,
        'CDLHARAMICROSS': talib.CDLHARAMICROSS,
        'CDLHIGHWAVE': talib.CDLHIGHWAVE,
        'CDLHIKKAKE': talib.CDLHIKKAKE,
        'CDLHIKKAKEMOD': talib.CDLHIKKAKEMOD,
        'CDLHOMINGPIGEON': talib.CDLHOMINGPIGEON,
        'CDLIDENTICAL3CROWS': talib.CDLIDENTICAL3CROWS,
        'CDLINNECK': talib.CDLINNECK,
        'CDLINVERTEDHAMMER': talib.CDLINVERTEDHAMMER,
        'CDLKICKING': talib.CDLKICKING,
        'CDLKICKINGBYLENGTH': talib.CDLKICKINGBYLENGTH,
        'CDLLADDERBOTTOM': talib.CDLLADDERBOTTOM,
        'CDLLONGLEGGEDDOJI': talib.CDLLONGLEGGEDDOJI,
        'CDLLONGLINE': talib.CDLLONGLINE,
        'CDLMARUBOZU': talib.CDLMARUBOZU,
        'CDLMATCHINGLOW': talib.CDLMATCHINGLOW,
        'CDLMATHOLD': talib.CDLMATHOLD,
        'CDLMORNINGDOJISTAR': talib.CDLMORNINGDOJISTAR,
        'CDLMORNINGSTAR': talib.CDLMORNINGSTAR,
        'CDLONNECK': talib.CDLONNECK,
        'CDLPIERCING': talib.CDLPIERCING,
        'CDLRICKSHAWMAN': talib.CDLRICKSHAWMAN,
        'CDLRISEFALL3METHODS': talib.CDLRISEFALL3METHODS,
        'CDLSEPARATINGLINES': talib.CDLSEPARATINGLINES,
        'CDLSHOOTINGSTAR': talib.CDLSHOOTINGSTAR,
    }

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¸€æ‹¬ã§è¨ˆç®—ã—ã¦ DataFrame ã«è¿½åŠ 
    for name, func in candlestick_patterns.items():
        df[name] = func(open_col, high_col, low_col, close_col)

    # ä¾‹: ç¿Œæ—¥ã®çµ‚å€¤ãŒå½“æ—¥ã®çµ‚å€¤ã‚ˆã‚Šé«˜ã‘ã‚Œã°1ã€ãã†ã§ãªã‘ã‚Œã°0
    df['long_target'] = (df['close'].shift(-1) > df['close']).astype(int)

    df.dropna(inplace=True)
    return df

# === ç›¸é–¢ä¿‚æ•°ã«ã‚ˆã‚‹ç‰¹å¾´é‡å‰Šé™¤é–¢æ•° ===
def select_features_pipeline(df, target_column, corr_threshold=0.9, top_n=10):
    # ç›®çš„å¤‰æ•°ã¨ 'close' åˆ—ã‚’é™¤ã„ãŸç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    features_df = df.drop(columns=[target_column, 'close'])

    # ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—
    corr_matrix = features_df.corr().abs()
    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > corr_threshold)]
    print(f"ğŸ› ï¸ å‰Šé™¤ã•ã‚ŒãŸé«˜ç›¸é–¢ç‰¹å¾´é‡: {to_drop}")
    reduced_df = features_df.drop(columns=to_drop)

    # LightGBMã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦ã®è¨ˆç®—
    X = reduced_df
    y = df[target_column]
    model = lgb.LGBMClassifier()
    model.fit(X, y)
    feature_importances = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values(by='importance', ascending=False)

    # ä¸Šä½ç‰¹å¾´é‡ã®é¸æŠ
    top_features = feature_importances.head(top_n)['feature'].tolist()
    print(f"ğŸŒŸ LightGBMã§é¸ã°ã‚ŒãŸä¸Šä½ {top_n} ç‰¹å¾´é‡: {top_features}")

    # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã¨ 'close' åˆ—ã€ç›®çš„å¤‰æ•°ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
    selected_df = df[top_features + ['close', target_column]]
    return selected_df

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
def create_lgbm_model():
    return lgb.LGBMRegressor()

def create_xgboost_model():
    return xgb.XGBRegressor()

def create_catboost_model():
    return cb.CatBoostRegressor(silent=True)

def create_rf_model():
    return RandomForestRegressor()

# LSTMãƒ¢ãƒ‡ãƒ«å®šç¾©
class RNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(RNNModel, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])

def create_rnn_model(input_dim, hidden_dim=64, output_dim=1):
    return RNNModel(input_dim, hidden_dim, output_dim)

# Transformerãƒ¢ãƒ‡ãƒ«å®šç¾©
class TransformerModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TransformerModel, self).__init__()
        self.transformer = nn.Transformer(d_model=hidden_dim, num_encoder_layers=3)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        transformer_out = self.transformer(x)
        return self.fc(transformer_out[:, -1, :])

def create_transformer_model(input_dim, hidden_dim=64, output_dim=1):
    return TransformerModel(input_dim, hidden_dim, output_dim)

# Optunaã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
def optimize_model(trial, model_type, X_train, y_train):
    if model_type == 'xgboost':
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
            'learning_rate': trial.suggest_float("learning_rate", 1e-4, 1e-1, log=True),
            'subsample': trial.suggest_float("subsample", 0.6, 1.0),
        }
        model = xgb.XGBRegressor(**params)
    elif model_type == 'lightgbm':
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'learning_rate': trial.suggest_float("learning_rate", 1e-4, 1e-1, log=True),
            'num_leaves': trial.suggest_int('num_leaves', 30, 150),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
        }
        model = lgb.LGBMRegressor(**params)
    elif model_type == 'catboost':
        params = {
            'iterations': trial.suggest_int('iterations', 100, 1000),
            'learning_rate': trial.suggest_float("learning_rate", 1e-4, 1e-1, log=True),
            'depth': trial.suggest_int('depth', 3, 15),
        }
        model = cb.CatBoostRegressor(**params, silent=True)
    elif model_type == 'randomforest':
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        }
        model = RandomForestRegressor(**params)

    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ãŸè©•ä¾¡
    score = cross_val_score(model, X_train, y_train, cv=3, scoring='neg_mean_absolute_error')
    return score.mean()

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ï¼ˆstackingï¼‰
def create_ensemble_model(models, ensemble_type):
    if ensemble_type == 'stacking':
        ensemble_model = StackingRegressor(estimators=models)
    elif ensemble_type == 'blending':
        ensemble_model = VotingRegressor(estimators=models)
    elif ensemble_type == 'voting_hard':
        ensemble_model = VotingRegressor(estimators=models, voting='hard')
    elif ensemble_type == 'voting_soft':
        ensemble_model = VotingRegressor(estimators=models, voting='soft')
    return ensemble_model

# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–¢æ•°ï¼ˆä»®ã®ä¾‹ï¼‰
# å£²è²·ãƒ­ã‚¸ãƒƒã‚¯ã‚’å«ã‚€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–¢æ•°
def run_backtest(df, model, features):
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨
    predictions = model.predict(df[features])
    position = None
    entry_price = 0
    pnl = []
    trade_log = []
    equity_curve = [1.0]  # è³‡ç”£æ›²ç·šï¼ˆåˆæœŸè³‡ç”£ã‚’1.0ã¨ã™ã‚‹ï¼‰

    for i, pred in enumerate(predictions):
        close_price = df.iloc[i]['close']  # 'close' åˆ—ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’å‰æ

        # è²·ã„ã‚¨ãƒ³ãƒˆãƒªãƒ¼
        if position is None and pred == 1:  # äºˆæ¸¬ãŒ1ï¼ˆç¿Œæ—¥ä¸Šæ˜‡äºˆæ¸¬ï¼‰ã®å ´åˆ
            position = 'long'
            entry_price = close_price
            trade_log.append(('BUY', close_price))

        # å£²ã‚Šã‚¨ã‚°ã‚¸ãƒƒãƒˆ
        if position == 'long':
            stop_loss = entry_price * (1 - STOP_LOSS)
            take_profit = entry_price * (1 + TAKE_PROFIT)
            if close_price <= stop_loss or close_price >= take_profit:
                profit = close_price - entry_price - (close_price * COMMISSION + close_price * SLIPPAGE)
                pnl.append(profit)
                position = None
                trade_log.append(('SELL', close_price))
                # è³‡ç”£æ›²ç·šã‚’æ›´æ–°
                equity_curve.append(equity_curve[-1] * (1 + profit / entry_price))

    # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã®è¨ˆç®—
    daily_returns = np.diff(equity_curve) / equity_curve[:-1]
    sharpe_ratio = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252) if len(daily_returns) > 1 else 0

    # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã®è¨ˆç®—
    equity_curve_array = np.array(equity_curve)
    drawdown = equity_curve_array / np.maximum.accumulate(equity_curve_array) - 1
    max_drawdown = drawdown.min()

    # ç·æç›Šã¨å‹ç‡
    total_pnl = np.sum(pnl)
    win_rate = np.mean(np.array(pnl) > 0) if pnl else 0

    # çµæœã‚’è¾æ›¸å½¢å¼ã§è¿”ã™
    return {
        "total_pnl": total_pnl,
        "win_rate": win_rate,
        "sharpe_ratio": sharpe_ratio,
        "max_drawdown": max_drawdown,
        "equity_curve": equity_curve,
    }

def plot_asset_growth(asset_values):
    plt.plot(asset_values)
    plt.title('Asset Growth Over Time')
    plt.xlabel('Time')
    plt.ylabel('Asset Value')
    plt.show()

def generate_report(initial_capital, final_capital):
    total_return = (final_capital - initial_capital) / initial_capital
    print(f"Total Return: {total_return * 100:.2f}%")
    # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãªã©ä»–ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¿½åŠ 

def main():
    start_time = time.time()

    # 1. ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨å‰å‡¦ç†
    print("ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨å‰å‡¦ç†ã‚’é–‹å§‹...")
    df = get_data(TICKER, START_DATE, END_DATE, INTERVAL)
    df = preprocess_data(df)

    # ç‰¹å¾´é‡ç”Ÿæˆ
    print("ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    df = calc_features(df)

    # ç‰¹å¾´é‡é¸æŠ
    print("ç‰¹å¾´é‡é¸æŠã‚’é–‹å§‹...")
    df = select_features_pipeline(df, target_column='long_target', corr_threshold=0.9, top_n=20)

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«åˆ†å‰²
    FEATURES = [col for col in df.columns if col not in ['long_target']]
    X = df[FEATURES].values
    y = df['long_target'].values

    # 2. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    print("ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«åˆ†å‰²...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # 3. Optunaã§ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    print("ãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–ã‚’é–‹å§‹...")
    def objective(trial):
        model_type = 'xgboost'
        return optimize_model(trial, model_type, X_train, y_train)

    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=10)  # n_trialsã§è©¦è¡Œå›æ•°ã‚’èª¿æ•´
    print("æœ€é©åŒ–å®Œäº†ï¼æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š", study.best_params)

    # 4. ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    model = create_xgboost_model()
    model.set_params(**study.best_params)

    # 5. ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
    print("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹...")
    model.fit(X_train, y_train)

    # 6. äºˆæ¸¬ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    print("äºˆæ¸¬ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
    capital_results = run_backtest(df, model, FEATURES)

    # 7. è³‡ç”£æ¨ç§»ã®å¯è¦–åŒ–
    print("è³‡ç”£æ¨ç§»ã®ã‚°ãƒ©ãƒ•ã‚’æç”»...")
    plot_asset_growth(capital_results["equity_curve"])

    # 8. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print("æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º...")
    generate_report(10000, capital_results["equity_curve"][-1])  # åˆæœŸè³‡ç”£10000ã¨æœ€çµ‚è³‡ç”£å€¤ã‚’è¡¨ç¤º

    end_time = time.time()
    print(f"âœ… å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f} ç§’")

if __name__ == "__main__":
    main()
