# ========================== ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ==========================
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim

import talib
import yfinance as yf

from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.ensemble import StackingClassifier, RandomForestClassifier
import xgboost as xgb
import lightgbm as lgb
import catboost as catb

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# === å®šæ•°å®šç¾© ===
TICKER = '9684.T'
START_DATE = '2024-04-01'
END_DATE = '2025-04-10'
INTERVAL = '1d'
FEATURES = ['close_scaled']
STOP_LOSS_MODE = 1  # 1:å›ºå®šãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæåˆ‡ã‚Š 2:ãƒ‘ãƒ©ãƒœãƒªãƒƒã‚¯SARæåˆ‡ã‚Š 3:ç›´è¿‘å®‰å€¤æ›´æ–°
STOP_LOSS = 0.02    # å›ºå®šãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæåˆ‡ã‚Šã§ã®æå¤±è¨±å®¹ç‡ï¼ˆä¾‹:2%ï¼‰
TAKE_PROFIT = 0.04  # åˆ©ç¢ºå¹…ï¼ˆä¾‹:4%ï¼‰
COMMISSION = 0.0005  # æ‰‹æ•°æ–™ç‡ï¼ˆå¿…è¦ãªã‚‰è¨­å®šï¼‰
SLIPPAGE = 0.0005    # ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ç‡ï¼ˆå¿…è¦ãªã‚‰è¨­å®šï¼‰
SELECTED_MODELS = ['xgboost', 'randomforest', 'catboost', 'lightgbm']
ENSEMBLE_TYPE = 'stacking'  # 'blending', 'stacking', 'voting_hard', 'voting_soft'

# === ãƒ‡ãƒ¼ã‚¿å–å¾— ===
def fetch_data(ticker, start_date, end_date, interval):
    try:
        data = yf.download(ticker, start=start_date, end=end_date, interval=interval)
        print("[DEBUG] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç›´å¾Œã®ã‚«ãƒ©ãƒ :", data.columns.tolist())

        if data.empty:
            raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        expected_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        missing_cols = [col for col in expected_cols if col not in data.columns]
        if missing_cols:
            raise ValueError(f"[ERROR] å¿…è¦ãªåˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {missing_cols}")

        data = data[expected_cols].copy()
        data.columns = ['open', 'high', 'low', 'close', 'volume']

        print("[DEBUG] å°æ–‡å­—ã«å¤‰æ›å¾Œã®ã‚«ãƒ©ãƒ :", data.columns.tolist())
        return data

    except Exception as e:
        print(f"[ERROR] fetch_data å†…ã®ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# === ç‰¹å¾´é‡ç”Ÿæˆ ===
def calc_features(df):
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"å¿…è¦ãªåˆ—ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“: {missing_columns}")

    # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’å–å¾—ã—ã€numpy.ndarray å‹ã«å¤‰æ›
    open_col = df['open'].values.astype(float)
    high_col = df['high'].values.astype(float)
    low_col = df['low'].values.astype(float)
    close_col = df['close'].values.astype(float)
    volume = df['volume'].values.astype(float)

    orig_columns = df.columns

    hilo = (df['high'] + df['low']) / 2
    # ä¾¡æ ¼(hilo ã¾ãŸã¯ close)ã‚’å¼•ã„ãŸå¾Œã€ä¾¡æ ¼(close)ã§å‰²ã‚‹ã“ã¨ã§æ¨™æº–åŒ–ã—ã¦ã‚‹ã‚‚ã®ã‚ã‚Š

    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ã‚’è¨ˆç®—ã—ã¦ df ã«è¿½åŠ 
    df['BBANDS_upperband'], df['BBANDS_middleband'], df['BBANDS_lowerband'] = talib.BBANDS(
        df['close'], timeperiod=5, nbdevup=2, nbdevdn=2, matype=0
    )

    new_features = {
        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
        'BBANDS_upperband': (df['BBANDS_upperband'] - hilo) / df['close'],
        'BBANDS_middleband': (df['BBANDS_middleband'] - hilo) / df['close'],
        'BBANDS_lowerband': (df['BBANDS_lowerband'] - hilo) / df['close'],

        # ç§»å‹•å¹³å‡
        'DEMA': (talib.DEMA(close_col, timeperiod=30) - hilo) / close_col,
        'EMA': (talib.EMA(close_col, timeperiod=30) - hilo) / close_col,
        'EMA_short': (talib.EMA(close_col, timeperiod=5) - hilo) / close_col,
        'EMA_middle': (talib.EMA(close_col, timeperiod=20) - hilo) / close_col,
        'EMA_long': (talib.EMA(close_col, timeperiod=40) - hilo) / close_col,
        'HT_TRENDLINE': (talib.HT_TRENDLINE(close_col) - hilo) / close_col,
        'KAMA': (talib.KAMA(close_col, timeperiod=30) - hilo) / close_col,
        'MA': (talib.MA(close_col, timeperiod=30, matype=0) - hilo) / close_col,
        'MIDPOINT': (talib.MIDPOINT(close_col, timeperiod=14) - hilo) / close_col,
        'SMA': (talib.SMA(close_col, timeperiod=30) - hilo) / close_col,
        'T3': (talib.T3(close_col, timeperiod=5, vfactor=0) - hilo) / close_col,
        'HMA': talib.WMA(close_col, timeperiod=30),
        'TEMA': (talib.TEMA(close_col, timeperiod=30) - hilo) / close_col,
        'TRIMA': (talib.TRIMA(close_col, timeperiod=30) - hilo) / close_col,
        'WMA': (talib.WMA(close_col, timeperiod=30) - hilo) / close_col,

        # MACD
        'MACD_macd': talib.MACD(close_col, fastperiod=12, slowperiod=26, signalperiod=9)[0] / close_col,
        'MACD_macdsignal': talib.MACD(close_col, fastperiod=12, slowperiod=26, signalperiod=9)[1] / close_col,
        'MACD_macdhist': talib.MACD(close_col, fastperiod=12, slowperiod=26, signalperiod=9)[2] / close_col,

        # ç·šå½¢å›å¸°ç³»
        'LINEARREG': (talib.LINEARREG(close_col, timeperiod=14) - close_col) / close_col,
        'LINEARREG_SLOPE': talib.LINEARREG_SLOPE(close_col, timeperiod=14) / close_col,
        'LINEARREG_ANGLE': talib.LINEARREG_ANGLE(close_col, timeperiod=14),
        'LINEARREG_INTERCEPT': (talib.LINEARREG_INTERCEPT(close_col, timeperiod=14) - close_col) / close_col,

        # ADç³»
        'AD': talib.AD(high_col, low_col, close_col, volume) / close_col,
        'ADX': talib.ADX(high_col, low_col, close_col, timeperiod=14),
        'ADXR': talib.ADXR(high_col, low_col, close_col, timeperiod=14),
        'ADOSC': talib.ADOSC(high_col, low_col, close_col, volume, fastperiod=3, slowperiod=10) / close_col,
        'OBV': talib.OBV(close_col, volume) / close_col,

        # ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼ç³»
        'APO': talib.APO(close_col, fastperiod=12, slowperiod=26, matype=0) / close_col,
        'BOP': talib.BOP(open_col, high_col, low_col, close_col),
        'CCI': talib.CCI(high_col, low_col, close_col, timeperiod=14),
        'DX': talib.DX(high_col, low_col, close_col, timeperiod=14),
        'MFI': talib.MFI(high_col, low_col, close_col, volume, timeperiod=14),
        'MINUS_DI': talib.MINUS_DI(high_col, low_col, close_col, timeperiod=14),
        'PLUS_DI': talib.PLUS_DI(high_col, low_col, close_col, timeperiod=14),
        'MOM': talib.MOM(close_col, timeperiod=10) / close_col,
        'RSI': talib.RSI(close_col, timeperiod=14),
        'TRIX': talib.TRIX(close_col, timeperiod=30),
        'ULTOSC': talib.ULTOSC(high_col, low_col, close_col, timeperiod1=7, timeperiod2=14, timeperiod3=28),
        'WILLR': talib.WILLR(high_col, low_col, close_col, timeperiod=14),
        'SAR': talib.SAR(high_col, low_col, acceleration=0.02, maximum=0.2),

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»
        'MINUS_DM': talib.MINUS_DM(high_col, low_col, timeperiod=14) / close_col,
        'PLUS_DM': talib.PLUS_DM(high_col, low_col, timeperiod=14) / close_col,
        'STDDEV': talib.STDDEV(close_col, timeperiod=5, nbdev=1),
        'TRANGE': talib.TRANGE(high_col, low_col, close_col),
        'VAR': talib.VAR(close_col, timeperiod=5, nbdev=1),
        'ATR': talib.ATR(high_col, low_col, close_col, timeperiod=14),
        'NATR': talib.NATR(high_col, low_col, close_col, timeperiod=14),
        'VOLATILITY_index': talib.ATR(high_col, low_col, close_col, timeperiod=14) / talib.STDDEV(close_col, timeperiod=5, nbdev=1),

        # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
        'STOCH_slowk': talib.STOCH(high_col, low_col, close_col, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)[0],
        'STOCH_slowd': talib.STOCH(high_col, low_col, close_col, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)[1],
        'STOCHF_fastk': talib.STOCHF(high_col, low_col, close_col, fastk_period=5, fastd_period=3, fastd_matype=0)[0],
        'STOCHF_fastd': talib.STOCHF(high_col, low_col, close_col, fastk_period=5, fastd_period=3, fastd_matype=0)[1],
        'STOCHRSI_fastk': talib.STOCHRSI(close_col, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)[0],
        'STOCHRSI_fastd': talib.STOCHRSI(close_col, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)[1],

        # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›
        'HT_DCPERIOD': talib.HT_DCPERIOD(close_col),
        'HT_DCPHASE': talib.HT_DCPHASE(close_col),
        'HT_PHASOR_inphase': talib.HT_PHASOR(close_col)[0] / close_col,
        'HT_PHASOR_quadrature': talib.HT_PHASOR(close_col)[1] / close_col,
        'HT_SINE_sine': talib.HT_SINE(close_col)[0] / close_col,
        'HT_SINE_leadsine': talib.HT_SINE(close_col)[1] / close_col,
        'HT_TRENDMODE': talib.HT_TRENDMODE(close_col),

        # ãã®ä»–
        'ROC': talib.ROC(close_col, timeperiod=10) / close_col,
        'STDDEV': talib.STDDEV(close_col, timeperiod=5, nbdev=1) / close_col,
        'TRANGE': talib.TRANGE(high_col, low_col, close_col) / close_col,
        'AROON_aroondown': talib.AROON(high_col, low_col, timeperiod=14)[0],
        'AROON_aroonup': talib.AROON(high_col, low_col, timeperiod=14)[1],
        'AROONOSC': talib.AROONOSC(high_col, low_col, timeperiod=14),
        'BETA': talib.BETA(high_col, low_col, timeperiod=5),
        'CORREL': talib.CORREL(high_col, low_col, timeperiod=30),
        'Price_ratio': df['close'] / df['close'].shift(1),
        'HIGH_ratio': df['high'] / df['high'].shift(1),
        'LOW_ratio': df['low'] / df['low'].shift(1),

        # Lagç‰¹å¾´é‡
        'CLOSE_lag_1': df['close'].shift(1),
        'CLOSE_lag_5': df['close'].shift(5),
        'MOVIENG_avg_5': df['close'].rolling(window=5).mean(),

        # å‘¨æœŸæ€§ã®ç‰¹å¾´é‡
        'DAY_of_week': df.index.dayofweek,
        'IS_weekend': (df.index.dayofweek >= 5).astype(int),
        'MONTH': df.index.month,
        'SIN_day': np.sin(2 * np.pi * df.index.dayofweek / 7),
        'COS_day': np.cos(2 * np.pi * df.index.dayofweek / 7),
        'SIN_month': np.sin(2 * np.pi * df.index.month / 12),
        'COS_month': np.cos(2 * np.pi * df.index.month / 12),

        # ãƒªã‚¿ãƒ¼ãƒ³ç³»
        'log_return': np.log(df['close'] / df['close'].shift(1)),
        'return_1d': df['close'].pct_change(1),
        'return_5d': df['close'].pct_change(5),
        'return_10d': df['close'].pct_change(10),
        'return_20d': df['close'].pct_change(20),
        'return_ma_5': df['close'].pct_change(1).rolling(window=5).mean(),
        'return_ma_10': df['close'].pct_change(1).rolling(window=10).mean(),
        'volatility_5': df['close'].rolling(window=5).std(),
        'volatility_10': df['close'].rolling(window=10).std(),
        'range': df['high'] - df['low'],
        'volume_change': df['volume'].pct_change(1),

        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»
        'ma_5': df['close'].rolling(window=5).mean(),
        'ma_25': df['close'].rolling(window=25).mean(),
        'ma_75': df['close'].rolling(window=75).mean(),
        'ma_deviation_5': df['close'] / df['close'].rolling(window=5).mean() - 1,
        'ma_deviation_25': df['close'] / df['close'].rolling(window=25).mean() - 1,
        'ma_deviation_75': df['close'] / df['close'].rolling(window=75).mean() - 1,
        'momentum_5': df['close'] - df['close'].shift(5),
        'momentum_10': df['close'] - df['close'].shift(10),
        'momentum_20': df['close'] - df['close'].shift(20),
    }

    # ãƒ­ãƒ¼ã‚½ã‚¯è¶³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¾æ›¸ã«è¿½åŠ 
    candlestick_patterns = {
        'CDL2CROWS': talib.CDL2CROWS,
        'CDL3BLACKCROWS': talib.CDL3BLACKCROWS,
        'CDL3INSIDE': talib.CDL3INSIDE,
        'CDL3LINESTRIKE': talib.CDL3LINESTRIKE,
        'CDL3OUTSIDE': talib.CDL3OUTSIDE,
        'CDL3STARSINSOUTH': talib.CDL3STARSINSOUTH,
        'CDL3WHITESOLDIERS': talib.CDL3WHITESOLDIERS,
        'CDLABANDONEDBABY': talib.CDLABANDONEDBABY,
        'CDLADVANCEBLOCK': talib.CDLADVANCEBLOCK,
        'CDLBELTHOLD': talib.CDLBELTHOLD,
        'CDLBREAKAWAY': talib.CDLBREAKAWAY,
        'CDLCLOSINGMARUBOZU': talib.CDLCLOSINGMARUBOZU,
        'CDLCONCEALBABYSWALL': talib.CDLCONCEALBABYSWALL,
        'CDLCOUNTERATTACK': talib.CDLCOUNTERATTACK,
        'CDLDARKCLOUDCOVER': talib.CDLDARKCLOUDCOVER,
        'CDLDOJI': talib.CDLDOJI,
        'CDLDOJISTAR': talib.CDLDOJISTAR,
        'CDLDRAGONFLYDOJI': talib.CDLDRAGONFLYDOJI,
        'CDLENGULFING': talib.CDLENGULFING,
        'CDLEVENINGDOJISTAR': talib.CDLEVENINGDOJISTAR,
        'CDLEVENINGSTAR': talib.CDLEVENINGSTAR,
        'CDLGAPSIDESIDEWHITE': talib.CDLGAPSIDESIDEWHITE,
        'CDLGRAVESTONEDOJI': talib.CDLGRAVESTONEDOJI,
        'CDLHAMMER': talib.CDLHAMMER,
        'CDLHANGINGMAN': talib.CDLHANGINGMAN,
        'CDLHARAMI': talib.CDLHARAMI,
        'CDLHARAMICROSS': talib.CDLHARAMICROSS,
        'CDLHIGHWAVE': talib.CDLHIGHWAVE,
        'CDLHIKKAKE': talib.CDLHIKKAKE,
        'CDLHIKKAKEMOD': talib.CDLHIKKAKEMOD,
        'CDLHOMINGPIGEON': talib.CDLHOMINGPIGEON,
        'CDLIDENTICAL3CROWS': talib.CDLIDENTICAL3CROWS,
        'CDLINNECK': talib.CDLINNECK,
        'CDLINVERTEDHAMMER': talib.CDLINVERTEDHAMMER,
        'CDLKICKING': talib.CDLKICKING,
        'CDLKICKINGBYLENGTH': talib.CDLKICKINGBYLENGTH,
        'CDLLADDERBOTTOM': talib.CDLLADDERBOTTOM,
        'CDLLONGLEGGEDDOJI': talib.CDLLONGLEGGEDDOJI,
        'CDLLONGLINE': talib.CDLLONGLINE,
        'CDLMARUBOZU': talib.CDLMARUBOZU,
        'CDLMATCHINGLOW': talib.CDLMATCHINGLOW,
        'CDLMATHOLD': talib.CDLMATHOLD,
        'CDLMORNINGDOJISTAR': talib.CDLMORNINGDOJISTAR,
        'CDLMORNINGSTAR': talib.CDLMORNINGSTAR,
        'CDLONNECK': talib.CDLONNECK,
        'CDLPIERCING': talib.CDLPIERCING,
        'CDLRICKSHAWMAN': talib.CDLRICKSHAWMAN,
        'CDLRISEFALL3METHODS': talib.CDLRISEFALL3METHODS,
        'CDLSEPARATINGLINES': talib.CDLSEPARATINGLINES,
        'CDLSHOOTINGSTAR': talib.CDLSHOOTINGSTAR,
    }

    # ä¸€æ‹¬ã§ DataFrame ã«è¿½åŠ 
    df = pd.concat([df, pd.DataFrame(new_features)], axis=1)

    # ä¾‹: ç¿Œæ—¥ã®çµ‚å€¤ãŒå½“æ—¥ã®çµ‚å€¤ã‚ˆã‚Šé«˜ã‘ã‚Œã°1ã€ãã†ã§ãªã‘ã‚Œã°0
    df['target'] = (df['close'].shift(-1) > df['close']).astype(int)

    df.dropna(inplace=True)
    return df

# ========================== ç›¸é–¢é™¤å»é–¢æ•° ==========================
def remove_highly_correlated_features(df, threshold=0.9, exclude_columns=None):
    if exclude_columns is None:
        exclude_columns = ['open', 'high', 'low', 'close', 'volume']
    corr_matrix = df.corr().abs()
    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold) and column not in exclude_columns]
    print(f"ğŸ› ï¸ å‰Šé™¤ã•ã‚ŒãŸé«˜ç›¸é–¢ç‰¹å¾´é‡: {to_drop}")
    return df.drop(columns=to_drop)

# ========================== PyTorchç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ ==========================
class BaseTorchWrapper(BaseEstimator, ClassifierMixin):
    def __init__(self, model_class, input_dim, hidden_dim=64, num_layers=2, epochs=20, batch_size=32, lr=0.001, device=None):
        self.model_class = model_class
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.epochs = epochs
        self.batch_size = batch_size
        self.lr = lr
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.classes_ = None  # ã‚¯ãƒ©ã‚¹å±æ€§ã‚’åˆæœŸåŒ–

    def fit(self, X, y):
        # ã‚¯ãƒ©ã‚¹å±æ€§ã‚’è¨­å®š
        self.classes_ = np.unique(y)

        X = torch.tensor(X.values, dtype=torch.float32) if isinstance(X, pd.DataFrame) else torch.tensor(X, dtype=torch.float32)
        y = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1) if isinstance(y, pd.Series) else torch.tensor(y, dtype=torch.float32).unsqueeze(1)

        dataset = torch.utils.data.TensorDataset(X, y)
        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)
        self.model = self.model_class(self.input_dim, self.hidden_dim, self.num_layers).to(self.device)
        criterion = nn.BCEWithLogitsLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)

        self.model.train()
        for epoch in range(self.epochs):
            for batch_X, batch_y in loader:
                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
        return self

    def predict_proba(self, X):
        X = torch.tensor(X.values, dtype=torch.float32).to(self.device)
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(X)
            probs = torch.sigmoid(outputs).cpu().numpy()
        return np.hstack([1 - probs, probs])

    def predict(self, X):
        probs = self.predict_proba(X)[:, 1]
        return (probs > 0.5).astype(int)

# ========================== ãƒ¢ãƒ‡ãƒ«å®šç¾© (RNN/Transformer) ==========================
class SimpleRNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers):
        super(SimpleRNN, self).__init__()
        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, x):
        x = x.unsqueeze(1)
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return out

class SimpleTransformer(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers):
        super(SimpleTransformer, self).__init__()

        # nhead ã‚’ input_dim ã«åˆã‚ã›ã¦èª¿æ•´
        nhead = 4
        if input_dim % nhead != 0:
            nhead = 1  # å¿…è¦ã«å¿œã˜ã¦ nhead ã‚’ 1 ã«è¨­å®š

        encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.fc = nn.Linear(input_dim, 1)

    def forward(self, x):
        x = x.unsqueeze(1)
        out = self.transformer(x)
        out = self.fc(out[:, -1, :])
        return out

# ========================== Baseãƒ¢ãƒ‡ãƒ«ä½œæˆ ==========================
def get_base_models(FEATURES):
    models = {
        'lgb': lgb.LGBMClassifier(random_state=42),
        'xgb': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
        'cat': catb.CatBoostClassifier(verbose=0, random_state=42),
        'rf': RandomForestClassifier(random_state=42),
        'rnn': BaseTorchWrapper(SimpleRNN, input_dim=len(FEATURES), epochs=30),
        'transformer': BaseTorchWrapper(SimpleTransformer, input_dim=len(FEATURES), epochs=30)
    }
    return models

# ========================== Stackingãƒ¢ãƒ‡ãƒ«ä½œæˆ ==========================
def build_stacking(models):
    estimators = [(name, model) for name, model in models.items()]
    stack_model = StackingClassifier(estimators=estimators, final_estimator=lgb.LGBMClassifier())
    return stack_model

# ========================== ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆè¶…ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰ ==========================
def run_backtest(df, model, FEATURES):
    initial_cash = 10000
    cash = initial_cash
    position = 0

    # ä¿®æ­£: df[FEATURES] ã‚’ãã®ã¾ã¾æ¸¡ã™
    preds = model.predict(df[FEATURES])
    df['preds'] = preds

    for i in range(1, len(df)):
        close_price = df['close'].iloc[i]

        # Buy Signal
        if df['preds'].iloc[i-1] == 1 and cash > 0:
            position = cash / close_price
            cash = 0
            print(f"ğŸ”¼ Buy at {close_price:.2f}, Position: {position:.4f}")

        # Sell Signal
        elif df['preds'].iloc[i-1] == 0 and position > 0:
            cash = position * close_price
            position = 0
            print(f"ğŸ”½ Sell at {close_price:.2f}, Cash: {cash:.2f}")

    # æœ€çµ‚è³‡ç”£ã‚’è¨ˆç®—
    final_value = cash + position * df['close'].iloc[-1]
    total_return = (final_value / initial_cash) - 1
    print(f"ğŸ“ˆ æœ€çµ‚è³‡ç”£: {final_value:.2f}å††ï¼ˆãƒªã‚¿ãƒ¼ãƒ³: {total_return*100:.2f}%ï¼‰")
    return final_value

# ========================== main ==========================
def main():
    # --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    df = fetch_data(TICKER, START_DATE, END_DATE, INTERVAL)
    if df is None:
        print("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # --- ç‰¹å¾´é‡ç”Ÿæˆ ---
    df = calc_features(df)

    # --- ç›¸é–¢é™¤å» ---
    print(f"ğŸ” ç›¸é–¢é™¤å»å‰ã®ç‰¹å¾´é‡æ•°: {df.shape[1]}åˆ—")
    df = remove_highly_correlated_features(df)
    print(f"âœ… ç›¸é–¢é™¤å»å¾Œã®ç‰¹å¾´é‡æ•°: {df.shape[1]}åˆ—")

    # --- ç‰¹å¾´é‡å®šç¾© ---
    FEATURES = [col for col in df.columns if col not in ['target']]

    # --- å­¦ç¿’ãƒ»è©•ä¾¡ ---
    X_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df['target'], test_size=0.2, random_state=42)

    base_models = get_base_models(FEATURES)
    ensemble_model = build_stacking(base_models)

    ensemble_model.fit(X_train, y_train)
    preds = ensemble_model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆç²¾åº¦: {acc:.4f}")

    # --- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ ---
    run_backtest(df, ensemble_model, FEATURES)

if __name__ == "__main__":
    main()
