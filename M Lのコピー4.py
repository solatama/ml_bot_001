# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
import seaborn as sns
import talib
import time
import optuna
import lightgbm as lgb
import xgboost as xgb
import catboost as cb
from scipy.stats import ttest_1samp
from sklearn.ensemble import RandomForestRegressor, StackingRegressor, VotingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# === å®šæ•°å®šç¾© ===
TICKER = '6836.T'
START_DATE = '2024-04-01'
END_DATE = '2025-04-10'
INTERVAL = '1d' # '1m' '5m' '15m' '30m' '1h' '1wk' '1mo'

FEATURES = ['close_scaled']
STOP_LOSS_MODE = 1  # 1: å›ºå®šãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæåˆ‡ã‚Š, 2: ãƒ‘ãƒ©ãƒœãƒªãƒƒã‚¯SARæåˆ‡ã‚Š, 3: ç›´è¿‘å®‰å€¤æ›´æ–°
STOP_LOSS = 0.02    # å›ºå®šãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæåˆ‡ã‚Šã§ã®æå¤±è¨±å®¹ç‡ï¼ˆä¾‹: 2%ï¼‰
TAKE_PROFIT = 0.04  # åˆ©ç¢ºå¹…ï¼ˆä¾‹: 4%ï¼‰
COMMISSION = 0.0005  # æ‰‹æ•°æ–™ç‡ï¼ˆå¿…è¦ãªã‚‰è¨­å®šï¼‰
SLIPPAGE = 0.0005    # ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ç‡ï¼ˆå¿…è¦ãªã‚‰è¨­å®šï¼‰
SELECTED_MODELS = ['xgboost', 'randomforest', 'catboost', 'lightgbm', 'rnn', 'transformer']
ENSEMBLE_TYPE = 'stacking'  # 'blending', 'stacking', 'voting_hard', 'voting_soft'ã‹ã‚‰é¸æŠ

# yfinanceã‚’ä½¿ã£ã¦æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
def get_data(ticker, start_date, end_date, interval='1d'):
    df = yf.download(ticker, start=start_date, end=end_date, interval=interval)
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']]

    # MultiIndex ã®å ´åˆã«ãƒªã‚»ãƒƒãƒˆ
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(0)

    # åˆ—åã‚’å°æ–‡å­—ã«å¤‰æ›
    df.columns = [col.lower() for col in df.columns]
    return df

# ãƒ‡ãƒ¼ã‚¿å–å¾—
df = get_data(TICKER, START_DATE, END_DATE, INTERVAL)
df.head()

# === ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–¢æ•° ===
def preprocess_data(df):
    # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
    df['cum_ret'] = df['close'].pct_change().cumsum()  # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³
    return df

# === tæ¤œå®šé–¢æ•° ===
def perform_t_test(df):
    x = df['cum_ret'].diff(1).dropna()  # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã®å·®åˆ†ã‚’è¨ˆç®—
    t, p = ttest_1samp(x, 0)  # tæ¤œå®šã‚’å®Ÿè¡Œ
    return t, p

# === på¹³å‡æ³•è¨ˆç®—é–¢æ•° ===
def calc_p_mean(x, n):
    ps = []
    for i in range(n):
        x2 = x[i * x.size // n:(i + 1) * x.size // n]
        if np.std(x2) == 0:
            ps.append(1)
        else:
            t, p = ttest_1samp(x2, 0)
            if t > 0:
                ps.append(p)
            else:
                ps.append(1)
    return np.mean(ps)

def calc_p_mean_type1_error_rate(p_mean, n):
    return (p_mean * n) ** n / math.factorial(n)

# === çµæœè¡¨ç¤ºé–¢æ•° ===
def display_results(df):
    # tæ¤œå®š
    print("tæ¤œå®šã‚’å®Ÿè¡Œä¸­...")
    x = df['cum_ret'].diff(1).dropna()
    t, p = perform_t_test(df)

    # på¹³å‡æ³•
    print("\npå¹³å‡æ³•ã‚’è¨ˆç®—ä¸­...")
    p_mean_n = 5
    p_mean = calc_p_mean(x, p_mean_n)
    error_rate = calc_p_mean_type1_error_rate(p_mean, p_mean_n)

    # çµæœã‚’è¾æ›¸å½¢å¼ã§è¿”ã™
    return {
        "tå€¤": t,
        "på€¤": p,
        "på¹³å‡æ³•_n": p_mean_n,
        "på¹³å‡": p_mean,
        "ã‚¨ãƒ©ãƒ¼ç‡": error_rate
    }

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆMinMaxScalerã‚’ä½¿ç”¨ï¼‰
def preprocess_data(df):
    if 'close' not in df.columns:
        raise ValueError("Error: 'close' åˆ—ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆMinMaxScalerã‚’ä½¿ç”¨ï¼‰
    scaler = MinMaxScaler()
    df['close_scaled'] = scaler.fit_transform(df[['close']])
    return df

def calc_features(df):
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"å¿…è¦ãªåˆ—ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“: {missing_columns}")

    # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’å–å¾—ã—ã€numpy.ndarray å‹ã«å¤‰æ›
    open_col = df['open'].values.astype(float)
    high_col = df['high'].values.astype(float)
    low_col = df['low'].values.astype(float)
    close_col = df['close'].values.astype(float)
    volume = df['volume'].values.astype(float)

    orig_columns = df.columns

    hilo = (df['high'] + df['low']) / 2
    # ä¾¡æ ¼(hilo ã¾ãŸã¯ close)ã‚’å¼•ã„ãŸå¾Œã€ä¾¡æ ¼(close)ã§å‰²ã‚‹ã“ã¨ã§æ¨™æº–åŒ–ã—ã¦ã‚‹ã‚‚ã®ã‚ã‚Š

    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
    df['BBANDS_upperband'], df['BBANDS_middleband'], df['BBANDS_lowerband'] = talib.BBANDS(df['close'], timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)
    df['BBANDS_upperband'] = (df['BBANDS_upperband'] - hilo) / df['close']
    df['BBANDS_middleband'] = (df['BBANDS_middleband'] - hilo) / df['close']
    df['BBANDS_lowerband'] = (df['BBANDS_lowerband'] - hilo) / df['close']

    # ç§»å‹•å¹³å‡
    df['DEMA'] = (talib.DEMA(close_col, timeperiod=30) - hilo) / close_col
    df['EMA'] = (talib.EMA(close_col, timeperiod=30) - hilo) / close_col
    df['EMA_short'] = (talib.EMA(close_col, timeperiod=5) - hilo) / close_col
    df['EMA_middle'] = (talib.EMA(close_col, timeperiod=20) - hilo) / close_col
    df['EMA_long'] = (talib.EMA(close_col, timeperiod=40) - hilo) / close_col
    df['HT_TRENDLINE'] = (talib.HT_TRENDLINE(close_col) - hilo) / close_col
    df['KAMA'] = (talib.KAMA(close_col, timeperiod=30) - hilo) / close_col
    df['MA'] = (talib.MA(close_col, timeperiod=30, matype=0) - hilo) / close_col
    df['MIDPOINT'] = (talib.MIDPOINT(close_col, timeperiod=14) - hilo) / close_col
    df['SMA'] = (talib.SMA(close_col, timeperiod=30) - hilo) / close_col
    df['T3'] = (talib.T3(close_col, timeperiod=5, vfactor=0) - hilo) / close_col
    df['HMA'] = talib.WMA(close_col, timeperiod=30)
    df['TEMA'] = (talib.TEMA(close_col, timeperiod=30) - hilo) / close_col
    df['TRIMA'] = (talib.TRIMA(close_col, timeperiod=30) - hilo) / close_col
    df['WMA'] = (talib.WMA(close_col, timeperiod=30) - hilo) / close_col

    # MACD
    df['MACD_macd'], df['MACD_macdsignal'], df['MACD_macdhist'] = talib.MACD(close_col, fastperiod=12, slowperiod=26, signalperiod=9) # Use close_col instead of close
    df['MACD_macd'] /= close_col # Use close_col instead of close
    df['MACD_macdsignal'] /= close_col # Use close_col instead of close
    df['MACD_macdhist'] /= close_col # Use close_col instead of close
    df['MACD_EXT'], df['MACD_SIGNAL_EXT'], df['MACD_HIST_EXT'] = talib.MACDEXT(close_col, fastperiod=12, slowperiod=26, signalperiod=9, fastmatype=0, slowmatype=0, signalmatype=0) # Use close_col instead of close

    # ç·šå½¢å›å¸°ç³»
    df['LINEARREG'] = (talib.LINEARREG(close_col, timeperiod=14) - close_col) / close_col # Use close_col instead of close
    df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(close_col, timeperiod=14) / close_col # Use close_col instead of close
    df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(close_col, timeperiod=14) # Use close_col instead of close
    df['LINEARREG_INTERCEPT'] = (talib.LINEARREG_INTERCEPT(close_col, timeperiod=14) - close_col) / close_col # Use close_col instead of close

    # ADç³»
    df['AD'] = talib.AD(high_col, low_col, close_col, volume) / close_col # Use high_col, low_col, close_col instead of high, low, close
    df['ADX'] = talib.ADX(high_col, low_col, close_col, timeperiod=14) # Use high_col, low_col, close_col instead of high, low, close
    df['ADXR'] = talib.ADXR(high_col, low_col, close_col, timeperiod=14) # Use high_col, low_col, close_col instead of high, low, close
    df['ADOSC'] = talib.ADOSC(high_col, low_col, close_col, volume, fastperiod=3, slowperiod=10) / close_col # Use high_col, low_col, close_col instead of high, low, close
    df['OBV'] = talib.OBV(close_col, volume) / close_col # Use close_col instead of close

    # ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼ç³»
    df['APO'] = talib.APO(close_col, fastperiod=12, slowperiod=26, matype=0) / close_col  # Changed close to close_col
    df['BOP'] = talib.BOP(open_col, high_col, low_col, close_col)  # Changed open, high, low, close to their respective _col variables
    df['CCI'] = talib.CCI(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['DX'] = talib.DX(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['MFI'] = talib.MFI(high_col, low_col, close_col, volume, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['MINUS_DI'] = talib.MINUS_DI(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['PLUS_DI'] = talib.PLUS_DI(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['MOM'] = talib.MOM(close_col, timeperiod=10) / close_col  # Changed close to close_col
    df['RSI'] = talib.RSI(close_col, timeperiod=14)  # Changed close to close_col
    df['TRIX'] = talib.TRIX(close_col, timeperiod=30)  # Changed close to close_col
    df['ULTOSC'] = talib.ULTOSC(high_col, low_col, close_col, timeperiod1=7, timeperiod2=14, timeperiod3=28)  # Changed high, low, close to their respective _col variables
    df['WILLR'] = talib.WILLR(high_col, low_col, close_col, timeperiod=14)  # Changed high, low, close to their respective _col variables
    df['SAR'] = talib.SAR(high_col, low_col, acceleration=0.02, maximum=0.2)  # Changed high, low to their respective _col variables

    # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
    df['STOCH_slowk'], df['STOCH_slowd'] = talib.STOCH(high_col, low_col, close_col, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0) # Changed high, low, close to high_col, low_col, close_col
    df['STOCHF_fastk'], df['STOCHF_fastd'] = talib.STOCHF(high_col, low_col, close_col, fastk_period=5, fastd_period=3, fastd_matype=0) # Changed high, low, close to high_col, low_col, close_col
    df['STOCHRSI_fastk'], df['STOCHRSI_fastd'] = talib.STOCHRSI(close_col, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0) # Changed close to close_col

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»
    df['MINUS_DM'] = talib.MINUS_DM(high_col, low_col, timeperiod=14) / close_col # Changed high, low, close to high_col, low_col, close_col
    df['PLUS_DM'] = talib.PLUS_DM(high_col, low_col, timeperiod=14) / close_col # Changed high, low, close to high_col, low_col, close_col
    df['STDDEV'] = talib.STDDEV(close_col, timeperiod=5, nbdev=1) # Changed close to close_col
    df['TRANGE'] = talib.TRANGE(high_col, low_col, close_col) # Changed high, low, close to high_col, low_col, close_col
    df['VAR'] = talib.VAR(close_col, timeperiod=5, nbdev=1) # Changed close to close_col
    df['ATR'] = talib.ATR(high_col, low_col, close_col, timeperiod=14) # Changed high, low, close to high_col, low_col, close_col
    df['NATR'] = talib.NATR(high_col, low_col, close_col, timeperiod=14) # Changed high, low, close to high_col, low_col, close_col
    df['VOLATILITY_index'] = df['ATR'] / df['STDDEV']

    # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›
    df['HT_DCPERIOD'] = talib.HT_DCPERIOD(close_col) # Changed close to close_col
    df['HT_DCPHASE'] = talib.HT_DCPHASE(close_col) # Changed close to close_col
    df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = talib.HT_PHASOR(close_col) # Changed close to close_col
    df['HT_PHASOR_inphase'] /= close_col # Changed close to close_col
    df['HT_PHASOR_quadrature'] /= close_col # Changed close to close_col
    df['HT_SINE_sine'], df['HT_SINE_leadsine'] = talib.HT_SINE(close_col) # Changed close to close_col
    df['HT_SINE_sine'] /= close_col # Changed close to close_col
    df['HT_SINE_leadsine'] /= close_col # Changed close to close_col
    df['HT_TRENDMODE'] = talib.HT_TRENDMODE(close_col) # Changed close to close_col

    # ãã®ä»–
    df['ROC'] = talib.ROC(close_col, timeperiod=10) / close_col # Changed close to close_col
    df['STDDEV'] = talib.STDDEV(close_col, timeperiod=5, nbdev=1) / close_col # Changed close to close_col
    df['TRANGE'] = talib.TRANGE(high_col, low_col, close_col) / close_col # Changed high, low, close to high_col, low_col, close_col
    df['AROON_aroondown'], df['AROON_aroonup'] = talib.AROON(high_col, low_col, timeperiod=14) # Changed high, low to high_col, low_col
    df['AROONOSC'] = talib.AROONOSC(high_col, low_col, timeperiod=14) # Changed high, low to high_col, low_col
    df['BETA'] = talib.BETA(high_col, low_col, timeperiod=5) # Changed high, low to high_col, low_col
    df['CORREL'] = talib.CORREL(high_col, low_col, timeperiod=30) # Changed high, low to high_col, low_col
    df['Price_ratio'] = df['close'] / df['close'].shift(1)  # Changed df[close_col] to df['close']
    df['HIGH_ratio'] = df['high'] / df['high'].shift(1)  # Changed df[high_col] to df['high']
    df['LOW_ratio'] = df['low'] / df['low'].shift(1)  # Changed df[low_col] to df['low']

    # Lagç‰¹å¾´é‡
    df['CLOSE_lag_1'] = df['close'].shift(1)  # 1æ—¥é…ã‚Œã®çµ‚å€¤ # Changed df[close_col] to df['close']
    df['CLOSE_lag_5'] = df['close'].shift(5)  # 5æ—¥é…ã‚Œã®çµ‚å€¤ # Changed df[close_col] to df['close']
    df['MOVIENG_avg_5'] = df['close'].rolling(window=5).mean()  # 5æ—¥ç§»å‹•å¹³å‡ # Changed df[close_col] to df['close']
    # å‘¨æœŸæ€§ã®ç‰¹å¾´é‡
    df['DAY_of_week'] = df.index.dayofweek  # æ›œæ—¥ï¼ˆ0=æœˆæ›œæ—¥, 6=æ—¥æ›œæ—¥ï¼‰
    df['IS_weekend'] = (df['DAY_of_week'] >= 5).astype(int)  # é€±æœ«ã‹ã©ã†ã‹
    df['MONTH'] = df.index.month  # æœˆï¼ˆ1ã€œ12ï¼‰
    df['SIN_day'] = np.sin(2 * np.pi * df['DAY_of_week'] / 7)  # æ—¥å‘¨æœŸ
    df['COS_day'] = np.cos(2 * np.pi * df['DAY_of_week'] / 7)  # æ—¥å‘¨æœŸ
    df['SIN_month'] = np.sin(2 * np.pi * df['MONTH'] / 12)  # æœˆå‘¨æœŸ
    df['COS_month'] = np.cos(2 * np.pi * df['MONTH'] / 12)  # æœˆå‘¨æœŸ

    # ãƒªã‚¿ãƒ¼ãƒ³ç³»
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    df['return_1d'] = df['close'].pct_change(1)
    df['return_5d'] = df['close'].pct_change(5)
    df['return_10d'] = df['close'].pct_change(10)
    df['return_20d'] = df['close'].pct_change(20)

    df['return_ma_5'] = df['return_1d'].rolling(window=5).mean()
    df['return_ma_10'] = df['return_1d'].rolling(window=10).mean()

    df['volatility_5'] = df['close'].rolling(window=5).std()
    df['volatility_10'] = df['close'].rolling(window=10).std()

    df['range'] = df['high'] - df['low']

    df['volume_change'] = df['volume'].pct_change(1)

    # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»
    df['ma_5'] = df['close'].rolling(window=5).mean()
    df['ma_25'] = df['close'].rolling(window=25).mean()
    df['ma_75'] = df['close'].rolling(window=75).mean()

    df['ma_deviation_5'] = df['close'] / df['ma_5'] - 1
    df['ma_deviation_25'] = df['close'] / df['ma_25'] - 1
    df['ma_deviation_75'] = df['close'] / df['ma_75'] - 1

    # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆnæ—¥å‰æ¯”ï¼‰
    df['momentum_5'] = df['close'] - df['close'].shift(5)
    df['momentum_10'] = df['close'] - df['close'].shift(10)
    df['momentum_20'] = df['close'] - df['close'].shift(20)

    # --- ãƒ­ãƒ¼ã‚½ã‚¯è¶³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ50ç¨®é¡ï¼‰---
    # å€¤ã¯ +100: å¼·æ°—ã‚·ã‚°ãƒŠãƒ«, -100: å¼±æ°—ã‚·ã‚°ãƒŠãƒ«, 0: ã‚·ã‚°ãƒŠãƒ«ãªã—
    candlestick_patterns = {
        'CDL2CROWS': talib.CDL2CROWS,
        'CDL3BLACKCROWS': talib.CDL3BLACKCROWS,
        'CDL3INSIDE': talib.CDL3INSIDE,
        'CDL3LINESTRIKE': talib.CDL3LINESTRIKE,
        'CDL3OUTSIDE': talib.CDL3OUTSIDE,
        'CDL3STARSINSOUTH': talib.CDL3STARSINSOUTH,
        'CDL3WHITESOLDIERS': talib.CDL3WHITESOLDIERS,
        'CDLABANDONEDBABY': talib.CDLABANDONEDBABY,
        'CDLADVANCEBLOCK': talib.CDLADVANCEBLOCK,
        'CDLBELTHOLD': talib.CDLBELTHOLD,
        'CDLBREAKAWAY': talib.CDLBREAKAWAY,
        'CDLCLOSINGMARUBOZU': talib.CDLCLOSINGMARUBOZU,
        'CDLCONCEALBABYSWALL': talib.CDLCONCEALBABYSWALL,
        'CDLCOUNTERATTACK': talib.CDLCOUNTERATTACK,
        'CDLDARKCLOUDCOVER': talib.CDLDARKCLOUDCOVER,
        'CDLDOJI': talib.CDLDOJI,
        'CDLDOJISTAR': talib.CDLDOJISTAR,
        'CDLDRAGONFLYDOJI': talib.CDLDRAGONFLYDOJI,
        'CDLENGULFING': talib.CDLENGULFING,
        'CDLEVENINGDOJISTAR': talib.CDLEVENINGDOJISTAR,
        'CDLEVENINGSTAR': talib.CDLEVENINGSTAR,
        'CDLGAPSIDESIDEWHITE': talib.CDLGAPSIDESIDEWHITE,
        'CDLGRAVESTONEDOJI': talib.CDLGRAVESTONEDOJI,
        'CDLHAMMER': talib.CDLHAMMER,
        'CDLHANGINGMAN': talib.CDLHANGINGMAN,
        'CDLHARAMI': talib.CDLHARAMI,
        'CDLHARAMICROSS': talib.CDLHARAMICROSS,
        'CDLHIGHWAVE': talib.CDLHIGHWAVE,
        'CDLHIKKAKE': talib.CDLHIKKAKE,
        'CDLHIKKAKEMOD': talib.CDLHIKKAKEMOD,
        'CDLHOMINGPIGEON': talib.CDLHOMINGPIGEON,
        'CDLIDENTICAL3CROWS': talib.CDLIDENTICAL3CROWS,
        'CDLINNECK': talib.CDLINNECK,
        'CDLINVERTEDHAMMER': talib.CDLINVERTEDHAMMER,
        'CDLKICKING': talib.CDLKICKING,
        'CDLKICKINGBYLENGTH': talib.CDLKICKINGBYLENGTH,
        'CDLLADDERBOTTOM': talib.CDLLADDERBOTTOM,
        'CDLLONGLEGGEDDOJI': talib.CDLLONGLEGGEDDOJI,
        'CDLLONGLINE': talib.CDLLONGLINE,
        'CDLMARUBOZU': talib.CDLMARUBOZU,
        'CDLMATCHINGLOW': talib.CDLMATCHINGLOW,
        'CDLMATHOLD': talib.CDLMATHOLD,
        'CDLMORNINGDOJISTAR': talib.CDLMORNINGDOJISTAR,
        'CDLMORNINGSTAR': talib.CDLMORNINGSTAR,
        'CDLONNECK': talib.CDLONNECK,
        'CDLPIERCING': talib.CDLPIERCING,
        'CDLRICKSHAWMAN': talib.CDLRICKSHAWMAN,
        'CDLRISEFALL3METHODS': talib.CDLRISEFALL3METHODS,
        'CDLSEPARATINGLINES': talib.CDLSEPARATINGLINES,
        'CDLSHOOTINGSTAR': talib.CDLSHOOTINGSTAR,
    }

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¸€æ‹¬ã§è¨ˆç®—ã—ã¦ DataFrame ã«è¿½åŠ 
    for name, func in candlestick_patterns.items():
        df[name] = func(open_col, high_col, low_col, close_col)

    # ä¾‹: ç¿Œæ—¥ã®çµ‚å€¤ãŒå½“æ—¥ã®çµ‚å€¤ã‚ˆã‚Šé«˜ã‘ã‚Œã°1ã€ãã†ã§ãªã‘ã‚Œã°0
    df['long_target'] = (df['close'].shift(-1) > df['close']).astype(int)

    df.dropna(inplace=True)
    return df

# === ç›¸é–¢ä¿‚æ•°ã«ã‚ˆã‚‹ç‰¹å¾´é‡å‰Šé™¤é–¢æ•° ===
def select_features_pipeline(df, target_column, corr_threshold=0.9, top_n=10):
    # ç›®çš„å¤‰æ•°ã¨ 'close' åˆ—ã‚’é™¤ã„ãŸç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    features_df = df.drop(columns=[target_column, 'close'])

    # ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—
    corr_matrix = features_df.corr().abs()
    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > corr_threshold)]
    print(f"ğŸ› ï¸ å‰Šé™¤ã•ã‚ŒãŸé«˜ç›¸é–¢ç‰¹å¾´é‡: {to_drop}")
    reduced_df = features_df.drop(columns=to_drop)

    # LightGBMã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦ã®è¨ˆç®—
    X = reduced_df
    y = df[target_column]
    model = lgb.LGBMClassifier()
    model.fit(X, y)
    feature_importances = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values(by='importance', ascending=False)

    # ä¸Šä½ç‰¹å¾´é‡ã®é¸æŠ
    top_features = feature_importances.head(top_n)['feature'].tolist()
    print(f"ğŸŒŸ LightGBMã§é¸ã°ã‚ŒãŸä¸Šä½ {top_n} ç‰¹å¾´é‡: {top_features}")

    # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã¨ 'close' åˆ—ã€ç›®çš„å¤‰æ•°ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
    selected_df = df[top_features + ['close', target_column]]
    return selected_df

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
def create_lgbm_model():
    return lgb.LGBMRegressor()

def create_xgboost_model():
    return xgb.XGBRegressor()

def create_catboost_model():
    return cb.CatBoostRegressor(silent=True)

def create_rf_model():
    return RandomForestRegressor()

# LSTMãƒ¢ãƒ‡ãƒ«å®šç¾©
class RNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(RNNModel, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])

def create_rnn_model(input_dim, hidden_dim=64, output_dim=1):
    return RNNModel(input_dim, hidden_dim, output_dim)

# Transformerãƒ¢ãƒ‡ãƒ«å®šç¾©
class TransformerModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TransformerModel, self).__init__()
        self.transformer = nn.Transformer(d_model=hidden_dim, num_encoder_layers=3)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        transformer_out = self.transformer(x)
        return self.fc(transformer_out[:, -1, :])

def create_transformer_model(input_dim, hidden_dim=64, output_dim=1):
    return TransformerModel(input_dim, hidden_dim, output_dim)

# Optunaã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã‚’æœ€é©åŒ–ï¼‰
from sklearn.model_selection import KFold

from sklearn.model_selection import KFold

def optimize_model(trial, model_type, X_train, y_train):
    if model_type == 'xgboost':
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
            'learning_rate': trial.suggest_float("learning_rate", 1e-4, 1e-1, log=True),
            'subsample': trial.suggest_float("subsample", 0.6, 1.0),
        }
        model = xgb.XGBRegressor(**params)
    elif model_type == 'lightgbm':
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'learning_rate': trial.suggest_float("learning_rate", 1e-4, 1e-1, log=True),
            'num_leaves': trial.suggest_int('num_leaves', 30, 150),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
            'force_col_wise': True,
        }
        model = lgb.LGBMRegressor(**params)
    elif model_type == 'catboost':
        params = {
            'iterations': trial.suggest_int('iterations', 100, 1000),
            'learning_rate': trial.suggest_float("learning_rate", 1e-4, 1e-1, log=True),
            'depth': trial.suggest_int('depth', 3, 15),
        }
        model = cb.CatBoostRegressor(**params, silent=True)
    elif model_type == 'randomforest':
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        }
        model = RandomForestRegressor(**params)

    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®š
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    sharpe_ratios = []

    for train_index, test_index in kf.split(X_train):
        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]
        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]

        # ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        model.fit(X_train_fold, y_train_fold)

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã‚’è¨ˆç®—
        backtest_result = run_backtest(X_test_fold, model, FEATURES)
        sharpe_ratios.append(backtest_result['sharpe_ratio'])

    # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã®å¹³å‡ã‚’è¿”ã™
    return np.mean(sharpe_ratios) if sharpe_ratios else -np.inf

def run_walk_forward_backtest(df, model, features, n_splits=5):
    """
    ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    :param df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    :param model: ãƒ¢ãƒ‡ãƒ«
    :param features: ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
    :param n_splits: ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã®åˆ†å‰²æ•°
    :return: å„æœŸé–“ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®ãƒªã‚¹ãƒˆ
    """
    results = []
    split_size = len(df) // n_splits

    for i in range(n_splits):
        print(f"\n=== ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æœŸé–“ {i + 1}/{n_splits} ===")
        train_start = 0
        train_end = split_size * (i + 1)
        test_start = train_end
        test_end = split_size * (i + 2)

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        train_data = df.iloc[train_start:train_end]
        test_data = df.iloc[test_start:test_end]

        if len(test_data) == 0:
            break

        # ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        model.fit(train_data[features], train_data['long_target'])

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        backtest_result = run_backtest(test_data, model, features)
        results.append(backtest_result)

        # å„æœŸé–“ã®çµæœã‚’è¡¨ç¤º
        print(f"æœŸé–“ {i + 1} ã®çµæœ:")
        print(f"ç·æç›Š: {backtest_result['total_pnl']:.2f}")
        print(f"å‹ç‡: {backtest_result['win_rate']:.2%}")
        print(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {backtest_result['sharpe_ratio']:.2f}")
        print(f"æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {backtest_result['max_drawdown']:.2%}")

    return results

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ï¼ˆstackingï¼‰
def create_ensemble_model(models, ensemble_type):
    if ensemble_type == 'stacking':
        ensemble_model = StackingRegressor(estimators=models)
    elif ensemble_type == 'blending':
        ensemble_model = VotingRegressor(estimators=models)
    elif ensemble_type == 'voting_hard':
        ensemble_model = VotingRegressor(estimators=models, voting='hard')
    elif ensemble_type == 'voting_soft':
        ensemble_model = VotingRegressor(estimators=models, voting='soft')
    return ensemble_model

# å£²è²·ãƒ­ã‚¸ãƒƒã‚¯ã‚’å«ã‚€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–¢æ•°
def run_backtest(df, model, features):
    # ç‰¹å¾´é‡ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    missing_features = [feature for feature in features if feature not in df.columns]
    if missing_features:
        raise ValueError(f"Error: ä»¥ä¸‹ã®ç‰¹å¾´é‡ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“: {missing_features}")
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨
    predictions = model.predict(df[features])  # df[features] ã‚’ä½¿ç”¨ã—ã¦ç‰¹å¾´é‡åã‚’ä¿æŒ
    position = None
    entry_price = 0
    pnl = []
    trade_log = []
    equity_curve = [1.0]  # è³‡ç”£æ›²ç·šï¼ˆåˆæœŸè³‡ç”£ã‚’1.0ã¨ã™ã‚‹ï¼‰

    for i, pred in enumerate(predictions):
        close_price = df.iloc[i]['close']

        # è²·ã„ã‚¨ãƒ³ãƒˆãƒªãƒ¼
        if position is None and pred > 0.5:  # äºˆæ¸¬ãŒ1ï¼ˆç¿Œæ—¥ä¸Šæ˜‡äºˆæ¸¬ï¼‰ã®å ´åˆ
            position = 'long'
            entry_price = close_price
            trade_log.append(('BUY', close_price))

        # å£²ã‚Šã‚¨ã‚°ã‚¸ãƒƒãƒˆ
        if position == 'long':
            stop_loss = entry_price * (1 - STOP_LOSS)
            take_profit = entry_price * (1 + TAKE_PROFIT)
            if close_price <= stop_loss or close_price >= take_profit:
                profit = close_price - entry_price - (close_price * COMMISSION + close_price * SLIPPAGE)
                pnl.append(profit)
                position = None
                trade_log.append(('SELL', close_price))
                # è³‡ç”£æ›²ç·šã‚’æ›´æ–°
                equity_curve.append(equity_curve[-1] * (1 + profit / entry_price))
            else:
                # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’ç¶­æŒã™ã‚‹å ´åˆã€è³‡ç”£æ›²ç·šã‚’ãã®ã¾ã¾æ›´æ–°
                equity_curve.append(equity_curve[-1])

    # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã®è¨ˆç®—
    daily_returns = np.diff(equity_curve) / equity_curve[:-1]
    sharpe_ratio = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252) if len(daily_returns) > 1 else 0

    # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã®è¨ˆç®—
    equity_curve_array = np.array(equity_curve)
    drawdown = equity_curve_array / np.maximum.accumulate(equity_curve_array) - 1
    max_drawdown = drawdown.min()

    # ç·æç›Šã¨å‹ç‡
    total_pnl = np.sum(pnl)
    win_rate = np.mean(np.array(pnl) > 0) if pnl else 0

    # çµæœã‚’è¾æ›¸å½¢å¼ã§è¿”ã™
    return {
        "total_pnl": total_pnl,
        "win_rate": win_rate,
        "sharpe_ratio": sharpe_ratio,
        "max_drawdown": max_drawdown,
        "equity_curve": equity_curve,
    }

def plot_asset_growth(asset_values):
    plt.plot(asset_values)
    plt.title('Asset Growth Over Time')
    plt.xlabel('Time')
    plt.ylabel('Asset Value')
    plt.show()

def generate_report(initial_capital, final_capital):
    total_return = (final_capital - initial_capital) / initial_capital
    print(f"Total Return: {total_return * 100:.2f}%")
    return total_return
    # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãªã©ä»–ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¿½åŠ 

# === ãƒ¡ã‚¤ãƒ³é–¢æ•° ===
def main():
    start_time = time.time()

    # 1. ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨å‰å‡¦ç†
    print("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã„ã¾ã™...")
    df = get_data(TICKER, START_DATE, END_DATE, INTERVAL)  # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    print("ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ã—ã¦ã„ã¾ã™...")
    df = preprocess_data(df)  # å‰å‡¦ç†ã‚’å®Ÿè¡Œ

    # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
    df['return'] = df['close'].pct_change().fillna(0)
    df['cum_ret'] = (1 + df['return']).cumprod()

    # çµæœã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º
    print("çµæœã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™...")
    results = display_results(df)

    # ç‰¹å¾´é‡ç”Ÿæˆ
    print("ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    df = calc_features(df)

    # ç‰¹å¾´é‡é¸æŠ
    print("ç‰¹å¾´é‡é¸æŠã‚’é–‹å§‹...")
    df = select_features_pipeline(df, target_column='long_target', corr_threshold=0.9, top_n=20)

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«åˆ†å‰²
    FEATURES = [col for col in df.columns if col not in ['long_target']]
    print("ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡:", FEATURES)
    X = df[FEATURES]
    y = df['long_target']

    # 2. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    print("ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«åˆ†å‰²...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # 3. Optunaã§ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    print("ãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–ã‚’é–‹å§‹...")

    def objective(trial):
        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’é¸æŠï¼ˆä¾‹: 'xgboost', 'lightgbm', 'catboost', 'randomforest'ï¼‰
        model_type = trial.suggest_categorical('model_type', ['xgboost', 'lightgbm', 'catboost', 'randomforest'])
        return optimize_model(trial, model_type, X_train, y_train)

    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=10)  # n_trialsã§è©¦è¡Œå›æ•°ã‚’èª¿æ•´
    print("æœ€é©åŒ–å®Œäº†ï¼æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š", study.best_params)

    # 4. æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    model_type = study.best_params['model_type']
    params = {k: v for k, v in study.best_params.items() if k != 'model_type'}
    if model_type == 'xgboost':
        model = xgb.XGBRegressor(**params)
    elif model_type == 'lightgbm':
        model = lgb.LGBMRegressor(**params)
    elif model_type == 'catboost':
        model = cb.CatBoostRegressor(**params, silent=True)
    elif model_type == 'randomforest':
        model = RandomForestRegressor(**params)

    # 5. ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
    print("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹...")
    model.fit(X_train, y_train)

    # 6. äºˆæ¸¬ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    print("äºˆæ¸¬ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
    initial_capital = 10000  # åˆæœŸè³‡ç”£ã‚’å®šç¾©
    capital_results = run_backtest(df, model, FEATURES)
    final_capital = initial_capital * capital_results["equity_curve"][-1]  # æœ€çµ‚è³‡ç”£ã‚’è¨ˆç®—

    # 7. è³‡ç”£æ¨ç§»ã®å¯è¦–åŒ–
    print("è³‡ç”£æ¨ç§»ã®ã‚°ãƒ©ãƒ•ã‚’æç”»...")
    plot_asset_growth(capital_results["equity_curve"])

    # 8. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print("æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º...")
    generate_report(initial_capital, final_capital)

    # 9. ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã€æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã€ç·æç›Šã€å‹ç‡ã‚’è¡¨ç¤º
    print(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {capital_results['sharpe_ratio']:.2f}")
    print(f"æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {capital_results['max_drawdown']:.2%}")
    print(f"ç·æç›Š: {capital_results['total_pnl']:.2f}")
    print(f"å‹ç‡: {capital_results['win_rate']:.2%}")

    # 10. ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    print("\nã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’é–‹å§‹...")
    walk_forward_results = run_walk_forward_backtest(df, model, FEATURES, n_splits=5)

    # ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æã®çµæœã‚’é›†è¨ˆ
    total_pnl = sum(result['total_pnl'] for result in walk_forward_results)
    avg_sharpe_ratio = np.mean([result['sharpe_ratio'] for result in walk_forward_results])
    avg_max_drawdown = np.mean([result['max_drawdown'] for result in walk_forward_results])
    avg_win_rate = np.mean([result['win_rate'] for result in walk_forward_results])

    print("\nã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æã®ç·çµæœ:")
    print(f"ç·æç›Š: {total_pnl:.2f}")
    print(f"å¹³å‡ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {avg_sharpe_ratio:.2f}")
    print(f"å¹³å‡æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {avg_max_drawdown:.2%}")
    print(f"å¹³å‡å‹ç‡: {avg_win_rate:.2%}")

    # tæ¤œå®šã¨på¹³å‡æ³•ã®çµæœã‚’è¡¨ç¤º
    print("\nçµ±è¨ˆçš„æ¤œå®šçµæœ:")
    print(f"tå€¤: {results['tå€¤']:.5f}")
    print(f"på€¤: {results['på€¤']:.5f}")
    print(f"på¹³å‡æ³• n = {results['på¹³å‡æ³•_n']}")
    print(f"på¹³å‡: {results['på¹³å‡']:.5f}")
    print(f"ã‚¨ãƒ©ãƒ¼ç‡: {results['ã‚¨ãƒ©ãƒ¼ç‡']:.5e}")

    # ãƒ‡ãƒãƒƒã‚°ç”¨å‡ºåŠ›
    print(f"Initial Capital: {initial_capital}")
    print(f"Final Capital: {final_capital}")
    # print(f"Equity Curve: {capital_results['equity_curve']}")

    end_time = time.time()
    print(f"âœ… å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f} ç§’")

if __name__ == "__main__":
    main()
